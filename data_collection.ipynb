{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dissemenating Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Metadata\n",
    "- Here we will collect metadata from google scholar from NLP research from 2014-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_crossref_results(query, start_year, end_year, rows=1000, offset=0):\n",
    "    url = \"https://api.crossref.org/works\"\n",
    "    headers = {\"User-Agent\": \"NFacciola@my.gcu.edu\"}\n",
    "    \n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"filter\": f\"from-pub-date:{start_year}-01-01,until-pub-date:{end_year}-12-31\",\n",
    "        \"rows\": rows,\n",
    "        \"offset\": offset,\n",
    "        \"mailto\": \"NFacciola@my.gcu.edu\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Check if data is a dictionary and contains \"message\"\n",
    "    if isinstance(data, dict) and \"message\" in data:\n",
    "        # Check if \"items\" is present and is a list\n",
    "        if isinstance(data[\"message\"], dict) and \"items\" in data[\"message\"]:\n",
    "            return data[\"message\"][\"items\"]\n",
    "        else:\n",
    "            print(\"No 'items' found in 'message'.\")\n",
    "            return []\n",
    "    else:\n",
    "        print(\"Unexpected data format received from CrossRef API:\")\n",
    "        print(data)\n",
    "        return []\n",
    "\n",
    "def extract_metadata(item):\n",
    "    metadata = {\n",
    "        \"title\": item.get(\"title\", [None])[0],\n",
    "        \"doi\": item.get(\"DOI\"),\n",
    "        \"authors\": \", \".join([f\"{author.get('given')} {author.get('family')}\" for author in item.get(\"author\", [])]) if item.get(\"author\") else None,\n",
    "        \"publication_date\": item.get(\"created\", {}).get(\"date-time\"),\n",
    "        \"journal\": item.get(\"container-title\", [None])[0],\n",
    "        \"publisher\": item.get(\"publisher\"),\n",
    "        \"abstract\": item.get(\"abstract\"),\n",
    "        \"keywords\": \", \".join(item.get(\"subject\", [])) if \"subject\" in item else None,\n",
    "        \"references_count\": item.get(\"reference-count\"),\n",
    "        \"cited_by_count\": item.get(\"is-referenced-by-count\"),\n",
    "        \"funders\": \", \".join([funder.get(\"name\") for funder in item.get(\"funder\", [])]) if \"funder\" in item else None,\n",
    "        \"license\": item.get(\"license\", [{}])[0].get(\"URL\") if \"license\" in item else None,\n",
    "        \"url\": item.get(\"URL\"),\n",
    "        \"affiliations\": \", \".join([affil.get(\"name\") for affil in item.get(\"author\", [{}])[0].get(\"affiliation\", [])]) if \"author\" in item else None,\n",
    "    }\n",
    "    return metadata\n",
    "\n",
    "def collect_metadata(query, start_year=2014, end_year=2024, rows_per_request=1000, max_results=20000):\n",
    "    all_metadata = []\n",
    "    total_results = 0\n",
    "    offset = 0\n",
    "    \n",
    "    while total_results < max_results:\n",
    "        results = fetch_crossref_results(query, start_year, end_year, rows=rows_per_request, offset=offset)\n",
    "        \n",
    "        if not results:\n",
    "            break\n",
    "        \n",
    "        for item in results:\n",
    "            metadata = extract_metadata(item)\n",
    "            all_metadata.append(metadata)\n",
    "        \n",
    "        total_results += len(results)\n",
    "        offset += rows_per_request\n",
    "        time.sleep(1)  # Avoid hitting rate limits\n",
    "    \n",
    "    return all_metadata\n",
    "\n",
    "def save_metadata_to_csv(metadata, filename=\"crossref_nlp_metadata.csv\"):\n",
    "    df = pd.DataFrame(metadata)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved {len(metadata)} records to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 'items' found in 'message'.\n",
      "Saved 10000 records to crossref_nlp_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "query = \"Natural Language Processing\"\n",
    "metadata = collect_metadata(query, start_year=2014, end_year=2024, max_results=20000)\n",
    "save_metadata_to_csv(metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
